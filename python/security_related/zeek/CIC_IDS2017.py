import os
import pandas as pd
from datetime import datetime

def process_zeek_logs_CICIDS2017(pcap_file):
    pd.set_option('future.no_silent_downcasting', True)
    
    pcap_to_gt_map = {
  "../datasets/CIC-IDS2017/pcap/Monday-WorkingHours_00000_20170703135558.pcap": "../datasets/CIC-IDS2017/ground_truth/Monday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Monday-WorkingHours_00001_20170703143352.pcap": "../datasets/CIC-IDS2017/ground_truth/Monday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Monday-WorkingHours_00002_20170703145005.pcap": "../datasets/CIC-IDS2017/ground_truth/Monday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Monday-WorkingHours_00003_20170703180220.pcap": "../datasets/CIC-IDS2017/ground_truth/Monday-WorkingHours.csv",
  
  "../datasets/CIC-IDS2017/pcap/Tuesday-WorkingHours_00000_20170704135332.pcap": "../datasets/CIC-IDS2017/ground_truth/Tuesday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Tuesday-WorkingHours_00001_20170704142614.pcap": "../datasets/CIC-IDS2017/ground_truth/Tuesday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Tuesday-WorkingHours_00002_20170704144719.pcap": "../datasets/CIC-IDS2017/ground_truth/Tuesday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Tuesday-WorkingHours_00003_20170704182950.pcap": "../datasets/CIC-IDS2017/ground_truth/Tuesday-WorkingHours.csv",
  
  "../datasets/CIC-IDS2017/pcap/Wednesday-WorkingHours_00000_20170705134242.pcap": "../datasets/CIC-IDS2017/ground_truth/Wednesday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Wednesday-WorkingHours_00001_20170705135921.pcap": "../datasets/CIC-IDS2017/ground_truth/Wednesday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Wednesday-WorkingHours_00002_20170705154341.pcap": "../datasets/CIC-IDS2017/ground_truth/Wednesday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Wednesday-WorkingHours_00003_20170705164151.pcap": "../datasets/CIC-IDS2017/ground_truth/Wednesday-WorkingHours.csv",
  
  "../datasets/CIC-IDS2017/pcap/Thursday-WorkingHours_00000_20170706135858.pcap": "../datasets/CIC-IDS2017/ground_truth/Thursday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Thursday-WorkingHours_00001_20170706141854.pcap": "../datasets/CIC-IDS2017/ground_truth/Thursday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Thursday-WorkingHours_00002_20170706163710.pcap": "../datasets/CIC-IDS2017/ground_truth/Thursday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Thursday-WorkingHours_00003_20170706193716.pcap": "../datasets/CIC-IDS2017/ground_truth/Thursday-WorkingHours.csv",
  
  "../datasets/CIC-IDS2017/pcap/Friday-WorkingHours_00000_20170707135939.pcap": "../datasets/CIC-IDS2017/ground_truth/Friday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Friday-WorkingHours_00001_20170707142525.pcap": "../datasets/CIC-IDS2017/ground_truth/Friday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Friday-WorkingHours_00002_20170707160709.pcap": "../datasets/CIC-IDS2017/ground_truth/Friday-WorkingHours.csv",
  "../datasets/CIC-IDS2017/pcap/Friday-WorkingHours_00003_20170707201008.pcap": "../datasets/CIC-IDS2017/ground_truth/Friday-WorkingHours.csv"
}

    gt_path = pcap_to_gt_map.get(pcap_file) 
    if gt_path:
        df_gt = pd.read_csv(gt_path, low_memory=False)  
    else:
        print(f"No ground truth found for PCAP: {pcap_file}")
 
    column_mapping = {
    "Src IP": "src_ip",
    "Src Port": "src_port",
    "Dst IP": "dest_ip",
    "Dst Port": "dest_port",
    "Timestamp" : "start_time",
    "Protocol" : "proto",
    "Label": "flow_alerted"
    }

    df_gt.rename(columns=column_mapping, inplace=True)

    df_gt = df_gt[['src_ip', 'src_port', 'dest_ip', 'dest_port', 'proto', 'start_time', 'flow_alerted']]
    df_gt['flow_alerted'] = df_gt['flow_alerted'].apply(lambda x: False if x == 'BENIGN' else True)
    df_gt['src_port'] = pd.to_numeric(df_gt['src_port'], errors='coerce').astype('Int64')
    df_gt['dest_port'] = pd.to_numeric(df_gt['dest_port'], errors='coerce').astype('Int64')
    df_gt['proto'] = df_gt['proto'].replace({6: 'tcp', 17: 'udp', 0: 'hopopt', 1: 'icmp'})
    
    # +7200 because of timezone difference 
    df_gt['start_time'] = df_gt['start_time'].apply(lambda x: int(datetime.strptime(x.split('.')[0], '%Y-%m-%d %H:%M:%S').timestamp() + 7200) if pd.notnull(x) else None)    

    notice_log_file = './logs/notice.log'
    conn_log_file = './logs/conn.log'

    if not os.path.exists(conn_log_file and notice_log_file):
        print(f"No alerts generated by zeek")
        return(0,0,0,0,True)
    
    required_columns = {"id.orig_h", "id.orig_p", "id.resp_h", "id.resp_p", "proto"}

    df_notice = pd.read_json(notice_log_file, lines=True)

    if not required_columns.issubset(df_notice.columns):
        return (0, 0, 0, 0, True)

    df_notice.rename(columns={
        "id.orig_h": "src_ip",
        "id.orig_p": "src_port",
        "id.resp_h": "dest_ip",
        "id.resp_p": "dest_port",
    }, inplace=True)

    df_notice = df_notice[["src_ip", "src_port", "dest_ip", "dest_port", "proto"]]
    df_notice["flow_alerted"] = True 


    df_conn = pd.read_json(conn_log_file, lines=True)

    df_conn.rename(columns={
        "ts": "start_time",
        "id.orig_h": "src_ip",
        "id.orig_p": "src_port",
        "id.resp_h": "dest_ip",
        "id.resp_p": "dest_port",
    }, inplace=True)

    df_conn = df_conn[["src_ip", "src_port", "dest_ip", "dest_port", "proto", "start_time"]]

    df_zeek = pd.merge(df_conn, df_notice, how='left', on=['src_ip', 'dest_ip', 'src_port', 'dest_port', 'proto'])
    df_zeek = df_zeek.drop_duplicates(subset=["src_ip", "src_port", "dest_ip", "dest_port", "proto", "start_time"])

    df_zeek['flow_alerted'] = df_zeek['flow_alerted'].fillna(False)
    df_zeek["start_time"] = df_zeek["start_time"].astype(int)


    df_merged = pd.merge(df_gt, df_zeek, how='inner', on=['src_ip', 'dest_ip', 'src_port', 'dest_port', 'proto', 'start_time'],suffixes=('_gt', '_zeek'))
    df_merged['flow_alerted_zeek'] = df_merged['flow_alerted_zeek'].fillna(False)

    df_gt.to_csv("./tmp/df_gt.csv")
    df_zeek.to_csv("./tmp/df_zeek.csv")
    df_merged.to_csv("./tmp/df_merged.csv")



    df_tp = df_merged[(df_merged["flow_alerted_gt"] == True) & (df_merged["flow_alerted_zeek"] == True)]
    df_tn = df_merged[(df_merged["flow_alerted_gt"] == False) & (df_merged["flow_alerted_zeek"] == False)]
    df_fp = df_merged[(df_merged["flow_alerted_gt"] == False) & (df_merged["flow_alerted_zeek"] == True)]
    df_fn = df_merged[(df_merged["flow_alerted_gt"] == True) & (df_merged["flow_alerted_zeek"] == False)]
    
    tot_true_pos = tot_false_pos = tot_false_neg = tot_true_neg = 0

    tot_true_pos += len(df_tp)
    tot_false_pos += len(df_fp)
    tot_false_neg += len(df_fn)
    tot_true_neg += len(df_tn)

    return(tot_true_pos, tot_false_pos,tot_false_neg,tot_true_neg, False)


